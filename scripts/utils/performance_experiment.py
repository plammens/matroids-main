import dataclasses
import functools
import itertools as itt
import logging
import operator
import sys
import typing as tp

import matplotlib as mpl
import matplotlib.pyplot as plt
import matplotlib.style
import matplotlib.ticker
import matplotx.styles
import numpy as np
import tqdm

from utils.misc import ROOT_OUTPUT_PATH, ensure_directory_exists
from utils.plotting import plot_mean_and_range


logger = logging.getLogger(__name__)


MATPLOTLIB_STYLE = matplotx.styles.dufte | {
    "font.size": 10,
    "axes.titlesize": 12,
}
matplotlib.style.use(MATPLOTLIB_STYLE)

PLOT_KINDS = ("mean&std", "mean&range")


InputData = tp.Dict[str, tp.Any]  # keyword arguments
PerformanceMeasurements = tp.Dict[str, np.ndarray]


@dataclasses.dataclass
class PerformanceExperiment:
    """
    An experiment for measuring the execution time of a set of procedures.

    The dependent variable of a measurement is always execution time.
    This depends on a set of independent variables, only one of which is varied
    (so that the results can be visualised in a 2D plot).
    The given set of independent variables might not uniquely determine the input to the
    procedures being evaluated, in which case we need some way of generating
    (random) input data given the set of independent variables.

    - timer_functions: The timer functions to use. The keys are labels for the
        procedures being evaluated, and the values are timer functions, each of which
        takes some input data as keyword arguments and measures the execution time of
        a procedure (which should be deterministic with respect to its input data),
        returning time elapsed in seconds as a float.
    - x_name: Name of the independent variable that is varied (x). Used as the
        parameter name for passing the value to each of the timer functions.
    - x_range: Range of values for x.
    - fixed_variables: Names and values of independent variables that remain fixed,
        as a keyword argument dictionary.

    - input_generator: Generator function used to generate (random) input data given
        the values for x and the fixed variables as keyword arguments. Should return
        an iterator of dictionaries of keyword arguments (each representing a different
        input) to pass to each of the timer functions.
        Default is to pass the values of the variables unchanged.
    - generated_inputs: Number of different inputs (generated by ``input_generator``)
        to run each procedure with. Default is 1 (which together with the default
        generator implies that x plus the fixed variables should uniquely determine
        the input value).
    - repeats: Number of measurement repetitions per procedure, x value and input data.
        (This is to account for external factors which might affect the execution time.)

    - title: Title of the experiment (optional).
    """

    timer_functions: tp.Dict[str, tp.Callable[..., float]]
    x_name: str
    x_range: tp.Sequence
    fixed_variables: tp.Dict[str, tp.Any] = dataclasses.field(default_factory=dict)

    input_generator: tp.Callable[
        ..., tp.Iterable[InputData]
    ] = lambda **variables: itt.repeat(variables)
    generated_inputs: int = 1
    repeats: int = 10

    title: tp.Optional[str] = None

    def measure_performance(self) -> PerformanceMeasurements:
        """
        Run the experiment (gather measurements of execution time).

        :return: A dictionary mapping labels to 3-axis numpy arrays containing
            execution times as floats and indexed by
            (x value index, input data index, repetition).
        """
        results = {
            label: np.full(
                (len(self.x_range), self.generated_inputs, self.repeats),
                fill_value=np.nan,
            )
            for label in self.timer_functions
        }

        if self.title is not None:
            print(self.title, file=sys.stderr)

        for i, x_value in enumerate(tqdm.tqdm(self.x_range, desc="x values")):
            # generate inputs
            input_variables = self.fixed_variables | {self.x_name: x_value}
            input_generator_instance = self.input_generator(**input_variables)
            inputs = list(itt.islice(input_generator_instance, self.generated_inputs))

            for label, timer in tqdm.tqdm(
                self.timer_functions.items(),
                desc="algorithms",
                leave=False,
            ):
                times = results[label]
                for j, input_data in enumerate(
                    tqdm.tqdm(inputs, desc="generated inputs", leave=False)
                ):
                    for k in tqdm.trange(self.repeats, desc="repeats", leave=False):
                        times[i, j, k] = timer(**input_data)

        return results

    def plot_performance(
        self,
        ax: plt.Axes,
        measurements: PerformanceMeasurements,
        plot_kind: tp.Literal["mean&std", "mean&range"] = "mean&std",
    ) -> None:
        """
        Plot performance measurements obtained from :meth:`measure_performance`.

        Measurements are summarised as follows.
        First, for each value of x (the independent variable being varied) and each
        generated input, the minimum execution time among repetitions is computed
        (this is to account for external factors influencing execution time, such
        as the CPU load at the time of measurement).
        Then, for each value of x, among the various generated inputs, the mean and std
        of these minima is computed (this gives an estimate of expected execution time
        within the space of input instances determined by the independent variables).
        What is plotted is (for each procedure) these means +- std as errorbars (y axis)
        vs the x value (x axis).

        :param plot_kind: Plot plot_kind: mean +- std as error bars or mean with range
            as filled between solid color.
        :param ax: Axes object on which to plot.
        :param measurements: Measurements to plot, obtained from
            :meth:`measure_performance`.
        """
        if plot_kind not in PLOT_KINDS:
            raise ValueError(f"``plot_kind`` should be one of {PLOT_KINDS}")

        if self.title is not None:
            ax.set_title(self.title)
        ax.set_xlabel(self.x_name)
        ax.set_ylabel("time (s)")

        all_means = []
        for label, times in measurements.items():
            min_times_among_repetitions = np.min(times, axis=-1)
            means = min_times_among_repetitions.mean(axis=-1)
            all_means.append(means)

            if plot_kind == "mean&std":
                stds = min_times_among_repetitions.std(axis=-1)
                ax.errorbar(self.x_range, means, yerr=stds, marker=".", label=label)
            elif plot_kind == "mean&range":
                plot_mean_and_range(
                    ax,
                    self.x_range,
                    y=min_times_among_repetitions,
                    marker=".",
                    label=label,
                )
            else:
                assert False

        ax.set_ylim(bottom=0, top=1.05 * max(np.max(a) for a in all_means))
        ax.ticklabel_format(axis="y", scilimits=(-2, 2))

        ax.xaxis.set_major_formatter(mpl.ticker.EngFormatter())

    def measure_and_plot(self, ax: plt.Axes) -> None:
        """
        Combines measurement and plotting in one step.

        :param ax: Axes object on which to plot.
        """
        self.plot_performance(ax, self.measure_performance())


@dataclasses.dataclass
class PerformanceExperimentGroup:
    identifier: str
    title: str

    experiments: tp.Sequence[PerformanceExperiment]

    import cachetools
    from cachetools_ext.fs import FSLRUCache

    @cachetools.cached(cache=FSLRUCache(maxsize=100), key=lambda x: x.identifier)
    def measure_performance(self) -> tp.Tuple[PerformanceMeasurements, ...]:
        """Run each of the experiments in the group."""
        return tuple(e.measure_performance() for e in self.experiments)

    def plot_performance(
        self,
        all_measurements: tp.Sequence[PerformanceMeasurements],
        plot_kind: tp.Literal["mean&std", "mean&range"] = "mean&std",
        title: bool = True,
        legend_kwargs: tp.Dict[str, tp.Any] = None,
    ) -> plt.Figure:
        """Creates a new figure and plots the measurements of each experiment."""
        if legend_kwargs is None:
            legend_kwargs = {"loc": "center right"}

        fig, axes = plt.subplots(
            nrows=1,
            ncols=len(self.experiments),
            squeeze=False,
            sharey="row",
            figsize=[1 + 2.75 * len(self.experiments), 3.5],
        )
        fig: plt.Figure
        if title:
            fig.suptitle(self.title)

        for experiment, measurement, ax in zip(
            self.experiments, all_measurements, axes.flat
        ):
            experiment.plot_performance(ax, measurement, plot_kind=plot_kind)

        # legend - avoid duplicate labels
        artist_dicts = [
            dict(zip(labels, handles))
            for handles, labels in map(plt.Axes.get_legend_handles_labels, axes.flat)
        ]
        artist_dict = functools.reduce(operator.or_, artist_dicts)  # dict union
        fig.legend(artist_dict.values(), artist_dict.keys(), **legend_kwargs)

        fig.tight_layout()
        return fig

    def show_performance(
        self, all_measurements: tp.Sequence[PerformanceMeasurements], **kwargs
    ) -> None:
        self.plot_performance(all_measurements, **kwargs)
        plt.show()

    def save_performance_figure(
        self,
        all_measurements: tp.Sequence[PerformanceMeasurements],
        legend_kwargs: tp.Dict[str, tp.Any] = None,
        **kwargs,
    ):
        if legend_kwargs is None:
            legend_kwargs = {"loc": "upper left", "bbox_to_anchor": (1.0, 1.0)}
        fig = self.plot_performance(
            all_measurements, title=False, legend_kwargs=legend_kwargs, **kwargs
        )

        output_path = ROOT_OUTPUT_PATH / "figures" / f"{self.identifier}.pdf"
        logger.info(f"Saving figure for {self.identifier} to {output_path}")
        ensure_directory_exists(output_path.parent)
        fig.savefig(output_path, bbox_inches="tight")
        plt.close(fig)

    def measure_show_and_save(self, **kwargs) -> None:
        """Shortcut for running the experiments and showing the plot in one step."""
        measurements = self.measure_performance()
        legend_kwargs = kwargs.pop("legend_kwargs", None)
        self.show_performance(measurements, **kwargs)
        self.save_performance_figure(
            measurements, legend_kwargs=legend_kwargs, **kwargs
        )
